

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>biogeme.optimization &mdash; Biogeme 3.2.14 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=0b773b56"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Biogeme
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Install</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../code/toml.html">Configuration parameters</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../code/native_draws.html">Native draws</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../code/biogeme.html">.biogeme module</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Biogeme</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">biogeme.optimization</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for biogeme.optimization</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Optimization algorithms for Biogeme</span>

<span class="sd">:author: Michel Bierlaire</span>
<span class="sd">:date: Mon Dec 21 10:24:24 2020</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># There seems to be a bug in PyLint.</span>
<span class="c1"># pylint: disable=invalid-unary-operand-type, no-member</span>

<span class="c1"># Too constraining</span>
<span class="c1"># pylint: disable=invalid-name</span>
<span class="c1"># pylint: disable=too-many-lines, too-many-locals</span>
<span class="c1"># pylint: disable=too-many-arguments, too-many-branches</span>
<span class="c1"># pylint: disable=too-many-statements, too-many-return-statements</span>
<span class="c1"># pylint: disable=bare-except</span>


<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">biogeme_optimization.bounds</span><span class="w"> </span><span class="kn">import</span> <span class="n">Bounds</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">biogeme_optimization.diagnostics</span><span class="w"> </span><span class="kn">import</span> <span class="n">OptimizationResults</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">biogeme_optimization.function</span><span class="w"> </span><span class="kn">import</span> <span class="n">FunctionToMinimize</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">biogeme_optimization.linesearch</span><span class="w"> </span><span class="kn">import</span> <span class="n">newton_line_search</span><span class="p">,</span> <span class="n">bfgs_line_search</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">biogeme_optimization.simple_bounds</span><span class="w"> </span><span class="kn">import</span> <span class="n">simple_bounds_newton_algorithm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">biogeme_optimization.trust_region</span><span class="w"> </span><span class="kn">import</span> <span class="n">newton_trust_region</span><span class="p">,</span> <span class="n">bfgs_trust_region</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="scipy">
<a class="viewcode-back" href="../../code/biogeme/optimization.html#biogeme.optimization.scipy">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">scipy</span><span class="p">(</span>
    <span class="n">fct</span><span class="p">:</span> <span class="n">FunctionToMinimize</span><span class="p">,</span>
    <span class="n">init_betas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
    <span class="n">variable_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimization interface for Biogeme, based on the scipy</span>
<span class="sd">    minimize function.</span>

<span class="sd">    :param fct: object to calculate the objective function and its derivatives.</span>
<span class="sd">    :type fct: algorithms.functionToMinimize</span>

<span class="sd">    :param init_betas: initial value of the Beta parameters</span>
<span class="sd">    :type init_betas: numpy.array</span>

<span class="sd">    :param bounds: list of tuples (ell,u) containing the lower and upper bounds</span>
<span class="sd">          for each free parameter</span>
<span class="sd">    :type bounds: list(tuple)</span>

<span class="sd">    :param variable_names: names of the variables. Ignored</span>
<span class="sd">        here. Included to comply with the syntax.</span>
<span class="sd">    :type variable_names: list(str)</span>

<span class="sd">    :param parameters: dict of parameters to be transmitted to the</span>
<span class="sd">         optimization routine. See the `scipy`_ documentation.</span>

<span class="sd">    .. _`scipy`: https://docs.scipy.org/doc/scipy/reference/optimize.html</span>

<span class="sd">    :type parameters: dict(string:float or string)</span>

<span class="sd">    :return: named tuple:</span>

<span class="sd">            - betas is the solution found,</span>
<span class="sd">            - message is a dictionary reporting various aspects</span>
<span class="sd">              related to the run of the algorithm.</span>
<span class="sd">            - convergence is a bool which is True if the algorithm has converged</span>

<span class="sd">    :rtype: OptimizationResult</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">f_and_grad</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="n">fct</span><span class="o">.</span><span class="n">set_variables</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">function_data</span> <span class="o">=</span> <span class="n">fct</span><span class="o">.</span><span class="n">f_g</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">function_data</span><span class="o">.</span><span class="n">function</span><span class="p">,</span> <span class="n">function_data</span><span class="o">.</span><span class="n">gradient</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Optimization algorithm: scipy&#39;</span><span class="p">)</span>
    <span class="c1"># Absolute tolerance</span>
    <span class="n">absgtol</span> <span class="o">=</span> <span class="mf">1.0e-7</span>
    <span class="n">opts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ftol&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="s1">&#39;gtol&#39;</span><span class="p">:</span> <span class="n">absgtol</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">opts</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">}</span>

    <span class="k">if</span> <span class="s1">&#39;gtol&#39;</span> <span class="ow">in</span> <span class="n">opts</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Minimize with tol </span><span class="si">{</span><span class="n">opts</span><span class="p">[</span><span class="s2">&quot;gtol&quot;</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">f_and_grad</span><span class="p">,</span> <span class="n">init_betas</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">opts</span><span class="p">)</span>

    <span class="n">messages</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Algorithm&#39;</span><span class="p">:</span> <span class="s1">&#39;scipy.optimize&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Cause of termination&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">message</span><span class="p">,</span>
        <span class="s1">&#39;Number of iterations&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">nit</span><span class="p">,</span>
        <span class="s1">&#39;Number of function evaluations&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">nfev</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">OptimizationResults</span><span class="p">(</span>
        <span class="n">solution</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span> <span class="n">convergence</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">success</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="newton_linesearch_for_biogeme">
<a class="viewcode-back" href="../../code/biogeme/optimization.html#biogeme.optimization.newton_linesearch_for_biogeme">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">newton_linesearch_for_biogeme</span><span class="p">(</span>
    <span class="n">fct</span><span class="p">:</span> <span class="n">FunctionToMinimize</span><span class="p">,</span>
    <span class="n">init_betas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
    <span class="n">variable_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimization interface for Biogeme, based on Newton method.</span>

<span class="sd">    :param fct: object to calculate the objective function and its derivatives.</span>
<span class="sd">    :type fct: algorithms.functionToMinimize</span>

<span class="sd">    :param init_betas: initial value of the parameters.</span>
<span class="sd">    :type init_betas: numpy.array</span>

<span class="sd">    :param bounds: list of tuples (ell,u) containing the lower and</span>
<span class="sd">                   upper bounds for each free parameter. Note that</span>
<span class="sd">                   this algorithm does not support bound constraints.</span>
<span class="sd">                   Therefore, all the bounds will be ignored.</span>

<span class="sd">    :type bounds: list(tuples)</span>

<span class="sd">    :param variable_names: names of the variables.</span>
<span class="sd">    :type variable_names: list(str)</span>

<span class="sd">    :param parameters: dict of parameters to be transmitted to the</span>
<span class="sd">        optimization routine:</span>

<span class="sd">        - tolerance: when the relative gradient is below that</span>
<span class="sd">          threshold, the algorithm has reached convergence</span>
<span class="sd">          (default: :math:`\\varepsilon^{\\frac{1}{3}}`);</span>
<span class="sd">        - maxiter: the maximum number of iterations (default: 100).</span>

<span class="sd">    :type parameters: dict(string:float or int)</span>

<span class="sd">    :return: named tuple:</span>

<span class="sd">            - betas is the solution found,</span>
<span class="sd">            - message is a dictionary reporting various aspects</span>
<span class="sd">              related to the run of the algorithm.</span>
<span class="sd">            - convergence is a bool which is True if the algorithm has converged</span>

<span class="sd">    :rtype: OptimizationResults</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Optimization algorithm: Newton with line search [LS-newton]&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ell</span><span class="p">,</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">bounds</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ell</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warning_msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s1">&#39;This algorithm does not handle bound constraints. &#39;</span>
                <span class="s1">&#39;The bounds will be ignored.&#39;</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">warning_msg</span><span class="p">)</span>

    <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39;maxiter&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">maxiter</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;maxiter&#39;</span><span class="p">]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;** Optimization: Newton with linesearch&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">newton_line_search</span><span class="p">(</span>
        <span class="n">the_function</span><span class="o">=</span><span class="n">fct</span><span class="p">,</span> <span class="n">starting_point</span><span class="o">=</span><span class="n">init_betas</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="newton_trust_region_for_biogeme">
<a class="viewcode-back" href="../../code/biogeme/optimization.html#biogeme.optimization.newton_trust_region_for_biogeme">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">newton_trust_region_for_biogeme</span><span class="p">(</span>
    <span class="n">fct</span><span class="p">:</span> <span class="n">FunctionToMinimize</span><span class="p">,</span>
    <span class="n">init_betas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
    <span class="n">variable_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimization interface for Biogeme, based on Newton method with TR.</span>

<span class="sd">    :param fct: object to calculate the objective function and its derivatives.</span>
<span class="sd">    :type fct: algorithms.functionToMinimize</span>

<span class="sd">    :param init_betas: initial value of the parameters.</span>

<span class="sd">    :param bounds: list of tuples (ell, u) containing the lower and</span>
<span class="sd">                   upper bounds for each free parameter. Note that</span>
<span class="sd">                   this algorithm does not support bound constraints.</span>
<span class="sd">                   Therefore, all the bounds will be ignored.</span>
<span class="sd">    :type bounds: list(tuples)</span>

<span class="sd">    :param variable_names: names of the variables.</span>
<span class="sd">    :type variable_names: list(str)</span>

<span class="sd">    :param parameters: dict of parameters to be transmitted to the</span>
<span class="sd">        optimization routine:</span>

<span class="sd">        - tolerance: when the relative gradient is below that threshold,</span>
<span class="sd">          the algorithm has reached convergence</span>
<span class="sd">          (default:  :math:`\\varepsilon^{\\frac{1}{3}}`);</span>
<span class="sd">        - maxiter: the maximum number of iterations (default: 100).</span>
<span class="sd">        - dogleg: if True, the trust region subproblem is solved using</span>
<span class="sd">          the Dogleg method. If False, it is solved using the</span>
<span class="sd">          truncated conjugate gradient method (default: False).</span>
<span class="sd">        - radius: the initial radius of the truat region (default: 1.0).</span>

<span class="sd">    :type parameters: dict(string:float or int)</span>

<span class="sd">    :return: named tuple:</span>

<span class="sd">            - betas is the solution found,</span>
<span class="sd">            - message is a dictionary reporting various aspects</span>
<span class="sd">              related to the run of the algorithm.</span>
<span class="sd">            - convergence is a bool which is True if the algorithm has converged</span>

<span class="sd">    :rtype: OptimizationResults</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Optimization algorithm: Newton with trust region [TR-newton]&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ell</span><span class="p">,</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">bounds</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ell</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warning_msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s1">&#39;This algorithm does not handle bound constraints. &#39;</span>
                <span class="s1">&#39;The bounds will be ignored.&#39;</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">warning_msg</span><span class="p">)</span>

    <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">apply_dogleg</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">radius</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39;maxiter&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">maxiter</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;maxiter&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;dogleg&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">apply_dogleg</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;dogleg&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;radius&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">radius</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;radius&#39;</span><span class="p">]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;** Optimization: Newton with trust region&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">newton_trust_region</span><span class="p">(</span>
        <span class="n">the_function</span><span class="o">=</span><span class="n">fct</span><span class="p">,</span>
        <span class="n">starting_point</span><span class="o">=</span><span class="n">init_betas</span><span class="p">,</span>
        <span class="n">use_dogleg</span><span class="o">=</span><span class="n">apply_dogleg</span><span class="p">,</span>
        <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span>
        <span class="n">initial_radius</span><span class="o">=</span><span class="n">radius</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="bfgs_linesearch_for_biogeme">
<a class="viewcode-back" href="../../code/biogeme/optimization.html#biogeme.optimization.bfgs_linesearch_for_biogeme">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">bfgs_linesearch_for_biogeme</span><span class="p">(</span>
    <span class="n">fct</span><span class="p">:</span> <span class="n">FunctionToMinimize</span><span class="p">,</span>
    <span class="n">init_betas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
    <span class="n">variable_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimization interface for Biogeme, based on BFGS</span>
<span class="sd">    quasi-Newton method with LS.</span>

<span class="sd">    :param fct: object to calculate the objective function and its derivatives.</span>

<span class="sd">    :type fct: algorithms.functionToMinimize</span>

<span class="sd">    :param init_betas: initial value of the parameters.</span>

<span class="sd">    :param bounds: list of tuples (ell,u) containing the lower and</span>
<span class="sd">                   upper bounds for each free parameter. Note that</span>
<span class="sd">                   this algorithm does not support bound constraints.</span>
<span class="sd">                   Therefore, all the bounds will be ignored.</span>

<span class="sd">    :type bounds: list(tuples)</span>

<span class="sd">    :param variable_names: names of the variables.</span>
<span class="sd">    :type variable_names: list(str)</span>

<span class="sd">    :param parameters: dict of parameters to be transmitted to the</span>
<span class="sd">        optimization routine:</span>

<span class="sd">        - tolerance: when the relative gradient is below that</span>
<span class="sd">          threshold, the algorithm has reached convergence</span>
<span class="sd">          (default: :math:`\\varepsilon^{\\frac{1}{3}}`);</span>

<span class="sd">        - maxiter: the maximum number of iterations (default: 100).</span>

<span class="sd">        - | initBfgs: the positive definite matrix that initalizes the</span>
<span class="sd">                      BFGS updates. If None, the identity matrix is</span>
<span class="sd">                      used. Default: None.</span>


<span class="sd">    :type parameters: dict(string:float or int)</span>

<span class="sd">    :return: tuple x, messages, where</span>

<span class="sd">            - x is the solution found,</span>

<span class="sd">            - messages is a dictionary reporting various aspects</span>
<span class="sd">              related to the run of the algorithm.</span>

<span class="sd">    :rtype: numpy.array, dict(str:object)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Optimization algorithm: BFGS with line search [LS-BFGS]&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ell</span><span class="p">,</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">bounds</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ell</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warning_msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s1">&#39;This algorithm does not handle bound constraints. &#39;</span>
                <span class="s1">&#39;The bounds will be ignored.&#39;</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">warning_msg</span><span class="p">)</span>

    <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">init_bfgs</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39;maxiter&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">maxiter</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;maxiter&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;initBfgs&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">init_bfgs</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;initBfgs&#39;</span><span class="p">]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;** Optimization: BFGS with line search&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bfgs_line_search</span><span class="p">(</span>
        <span class="n">the_function</span><span class="o">=</span><span class="n">fct</span><span class="p">,</span>
        <span class="n">starting_point</span><span class="o">=</span><span class="n">init_betas</span><span class="p">,</span>
        <span class="n">init_bfgs</span><span class="o">=</span><span class="n">init_bfgs</span><span class="p">,</span>
        <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="bfgs_trust_region_for_biogeme">
<a class="viewcode-back" href="../../code/biogeme/optimization.html#biogeme.optimization.bfgs_trust_region_for_biogeme">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">bfgs_trust_region_for_biogeme</span><span class="p">(</span>
    <span class="n">fct</span><span class="p">:</span> <span class="n">FunctionToMinimize</span><span class="p">,</span>
    <span class="n">init_betas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
    <span class="n">variable_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimization interface for Biogeme, based on Newton method with TR.</span>

<span class="sd">    :param fct: object to calculate the objective function and its derivatives.</span>
<span class="sd">    :type fct: algorithms.functionToMinimize</span>

<span class="sd">    :param init_betas: initial value of the parameters.</span>

<span class="sd">    :param bounds: list of tuples (ell,u) containing the lower and</span>
<span class="sd">                   upper bounds for each free parameter. Note that</span>
<span class="sd">                   this algorithm does not support bound constraints.</span>
<span class="sd">                   Therefore, all the bounds will be ignored.</span>
<span class="sd">    :type bounds: list(tuples)</span>

<span class="sd">    :param variable_names: names of the variables.</span>
<span class="sd">    :type variable_names: list(str)</span>

<span class="sd">    :param parameters: dict of parameters to be transmitted to the</span>
<span class="sd">         optimization routine:</span>

<span class="sd">         - tolerance: when the relative gradient is below that</span>
<span class="sd">           threshold, the algorithm has reached convergence</span>
<span class="sd">           (default: :math:`\\varepsilon^{\\frac{1}{3}}`);</span>

<span class="sd">         - maxiter: the maximum number of iterations (default: 100).</span>

<span class="sd">         - dogleg: if True, the trust region subproblem is solved using</span>
<span class="sd">           the Dogleg method. If False, it is solved using the</span>
<span class="sd">           truncated conjugate gradient method (default: False).</span>

<span class="sd">         - radius: the initial radius of the truat region (default: 1.0).</span>

<span class="sd">         - initBfgs: the positive definite matrix that initalizes the</span>
<span class="sd">           BFGS updates. If None, the identity matrix is</span>
<span class="sd">           used. Default: None.</span>


<span class="sd">    :type parameters: dict(string:float or int)</span>

<span class="sd">    :return: tuple x, messages, where</span>

<span class="sd">            - x is the solution found,</span>
<span class="sd">            - messages is a dictionary reporting various aspects</span>
<span class="sd">              related to the run of the algorithm.</span>
<span class="sd">    :rtype: numpy.array, dict(str:object)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Optimization algorithm: BFGS with trust region [TR-BFGS]&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ell</span><span class="p">,</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">bounds</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ell</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">u</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warning_msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s1">&#39;This algorithm does not handle bound constraints. &#39;</span>
                <span class="s1">&#39;The bounds will be ignored.&#39;</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">warning_msg</span><span class="p">)</span>

    <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">apply_dogleg</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">radius</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">init_bfgs</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39;maxiter&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">maxiter</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;maxiter&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;dogleg&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">apply_dogleg</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;dogleg&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;radius&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">radius</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;radius&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;initBfgs&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">init_bfgs</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;initBfgs&#39;</span><span class="p">]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;** Optimization: BFGS with trust region&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bfgs_trust_region</span><span class="p">(</span>
        <span class="n">the_function</span><span class="o">=</span><span class="n">fct</span><span class="p">,</span>
        <span class="n">starting_point</span><span class="o">=</span><span class="n">init_betas</span><span class="p">,</span>
        <span class="n">init_bfgs</span><span class="o">=</span><span class="n">init_bfgs</span><span class="p">,</span>
        <span class="n">use_dogleg</span><span class="o">=</span><span class="n">apply_dogleg</span><span class="p">,</span>
        <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span>
        <span class="n">initial_radius</span><span class="o">=</span><span class="n">radius</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="simple_bounds_newton_algorithm_for_biogeme">
<a class="viewcode-back" href="../../code/biogeme/optimization.html#biogeme.optimization.simple_bounds_newton_algorithm_for_biogeme">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">simple_bounds_newton_algorithm_for_biogeme</span><span class="p">(</span>
    <span class="n">fct</span><span class="p">:</span> <span class="n">FunctionToMinimize</span><span class="p">,</span>
    <span class="n">init_betas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
    <span class="n">variable_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimization interface for Biogeme, based on variants of Newton</span>
<span class="sd">    method with simple bounds.</span>

<span class="sd">    :param fct: object to calculate the objective function and its derivatives.</span>
<span class="sd">    :type fct: algorithms.functionToMinimize</span>

<span class="sd">    :param init_betas: initial value of the parameters.</span>

<span class="sd">    :param bounds: list of tuples (ell,u) containing the lower and upper</span>
<span class="sd">                   bounds for each free</span>
<span class="sd">                   parameter. Note that this algorithm does not support bound</span>
<span class="sd">                   constraints.</span>
<span class="sd">                   Therefore, all the bounds will be ignored.</span>
<span class="sd">    :type bounds: list(tuples)</span>

<span class="sd">    :param variable_names: names of the variables.</span>
<span class="sd">    :type variable_names: list(str)</span>

<span class="sd">    :param parameters: dict of parameters to be transmitted to the</span>
<span class="sd">        optimization routine:</span>

<span class="sd">        - tolerance: when the relative gradient is below that threshold,</span>
<span class="sd">          the algorithm has reached convergence</span>
<span class="sd">          (default:  :math:`\\varepsilon^{\\frac{1}{3}}`);</span>
<span class="sd">        - steptol: the algorithm stops when the relative change in x</span>
<span class="sd">          is below this threshold. Basically, if p significant digits</span>
<span class="sd">          of x are needed, steptol should be set to 1.0e-p. Default:</span>
<span class="sd">          :math:`10^{-5}`</span>
<span class="sd">        - cgtolerance: when the norm of the residual is below that</span>
<span class="sd">          threshold, the conjugate gradient algorithm has reached</span>
<span class="sd">          convergence (default:  :math:`\\varepsilon^{\\frac{1}{3}}`);</span>
<span class="sd">        - proportionAnalyticalHessian: proportion (between 0 and 1) of</span>
<span class="sd">          iterations when the analytical Hessian is calculated (default: 1).</span>
<span class="sd">        - infeasibleConjugateGradient: if True, the conjugate gradient</span>
<span class="sd">          algorithm may generate infeasible solutiona until</span>
<span class="sd">          termination.  The result will then be projected on the</span>
<span class="sd">          feasible domain.  If False, the algorithm stops as soon as</span>
<span class="sd">          an infeasible iterate is generated (default: False).</span>
<span class="sd">        - maxiter: the maximum number of iterations (default: 1000).</span>
<span class="sd">        - radius: the initial radius of the trust region (default: 1.0).</span>
<span class="sd">        - eta1: threshold for failed iterations (default: 0.01).</span>
<span class="sd">        - eta2: threshold for very successful iteration (default 0.9).</span>
<span class="sd">        - enlargingFactor: factor used to enlarge the trust region</span>
<span class="sd">          during very successful iterations (default 10).</span>

<span class="sd">    :type parameters: dict(string:float or int)</span>

<span class="sd">    :return: x, messages</span>

<span class="sd">        - x is the solution generated by the algorithm,</span>
<span class="sd">        - messages is a dictionary describing information about the lagorithm</span>

<span class="sd">    :rtype: numpay.array, dict(str:object)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="s1">&#39;Optimization algorithm: hybrid Newton/BFGS with simple bounds [simple_bounds]&#39;</span>
    <span class="p">)</span>

    <span class="n">cgtol</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span> <span class="o">**</span> <span class="mf">0.3333</span>
    <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">radius</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">eta1</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">eta2</span> <span class="o">=</span> <span class="mf">0.9</span>
    <span class="n">proportion_true_hessian</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">enlarging_factor</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="c1"># We replace the default value by user defined value, if any.</span>
    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39;cgtolerance&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">cgtol</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;cgtolerance&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;maxiter&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">maxiter</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;maxiter&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;radius&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">radius</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;radius&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;eta1&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">eta1</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;eta1&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;eta2&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">eta2</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;eta2&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;enlargingFactor&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">enlarging_factor</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;enlargingFactor&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;proportionAnalyticalHessian&#39;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">proportion_true_hessian</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;proportionAnalyticalHessian&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">proportion_true_hessian</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;** Optimization: Newton with trust region for simple bounds&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">proportion_true_hessian</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;** Optimization: BFGS with trust region for simple bounds&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;** Optimization: Hybrid Newton &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">proportion_true_hessian</span><span class="si">}</span><span class="s1">%/BFGS &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;with trust region for simple bounds&#39;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">simple_bounds_newton_algorithm</span><span class="p">(</span>
        <span class="n">the_function</span><span class="o">=</span><span class="n">fct</span><span class="p">,</span>
        <span class="n">bounds</span><span class="o">=</span><span class="n">Bounds</span><span class="p">(</span><span class="n">bounds</span><span class="p">),</span>
        <span class="n">starting_point</span><span class="o">=</span><span class="n">init_betas</span><span class="p">,</span>
        <span class="n">variable_names</span><span class="o">=</span><span class="n">variable_names</span><span class="p">,</span>
        <span class="n">proportion_analytical_hessian</span><span class="o">=</span><span class="n">proportion_true_hessian</span><span class="p">,</span>
        <span class="n">first_radius</span><span class="o">=</span><span class="n">radius</span><span class="p">,</span>
        <span class="n">conjugate_gradient_tol</span><span class="o">=</span><span class="n">cgtol</span><span class="p">,</span>
        <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span>
        <span class="n">eta1</span><span class="o">=</span><span class="n">eta1</span><span class="p">,</span>
        <span class="n">eta2</span><span class="o">=</span><span class="n">eta2</span><span class="p">,</span>
        <span class="n">enlarging_factor</span><span class="o">=</span><span class="n">enlarging_factor</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="bio_newton">
<a class="viewcode-back" href="../../code/biogeme/optimization.html#biogeme.optimization.bio_newton">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">bio_newton</span><span class="p">(</span>
    <span class="n">fct</span><span class="p">:</span> <span class="n">FunctionToMinimize</span><span class="p">,</span>
    <span class="n">init_betas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
    <span class="n">variable_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimization interface for Biogeme, based on Newton&#39;s method with simple</span>
<span class="sd">    bounds.</span>

<span class="sd">    :param fct: object to calculate the objective function and its derivatives.</span>
<span class="sd">    :type fct: algorithms.functionToMinimize</span>

<span class="sd">    :param init_betas: initial value of the parameters.</span>

<span class="sd">    :param bounds: list of tuples (ell,u) containing the lower and upper</span>
<span class="sd">                   bounds for each free</span>
<span class="sd">                   parameter. Note that this algorithm does not support bound</span>
<span class="sd">                   constraints.</span>
<span class="sd">                   Therefore, all the bounds must be None.</span>
<span class="sd">    :type bounds: list(tuples)</span>

<span class="sd">    :param variable_names: names of the variables.</span>
<span class="sd">    :type variable_names: list(str)</span>

<span class="sd">    :param parameters: dict of parameters to be transmitted to the</span>
<span class="sd">        optimization routine:</span>

<span class="sd">        - tolerance: when the relative gradient is below that threshold,</span>
<span class="sd">          the algorithm has reached convergence</span>
<span class="sd">          (default:  :math:`\\varepsilon^{\\frac{1}{3}}`);</span>
<span class="sd">        - steptol: the algorithm stops when the relative change in x</span>
<span class="sd">          is below this threshold. Basically, if p significant digits</span>
<span class="sd">          of x are needed, steptol should be set to 1.0e-p. Default:</span>
<span class="sd">          :math:`10^{-5}`</span>
<span class="sd">        - cgtolerance: when the norm of the residual is below that</span>
<span class="sd">          threshold, the conjugate gradient algorithm has reached</span>
<span class="sd">          convergence (default:  :math:`\\varepsilon^{\\frac{1}{3}}`);</span>
<span class="sd">        - infeasibleConjugateGradient: if True, the conjugate</span>
<span class="sd">          gradient algorithm may generate until termination.  The</span>
<span class="sd">          result will then be projected on the feasible domain.  If</span>
<span class="sd">          False, the algorithm stops as soon as an infeasible iterate</span>
<span class="sd">          is generated (default: False).</span>
<span class="sd">        - maxiter: the maximum number of iterations (default: 1000).</span>
<span class="sd">        - radius: the initial radius of the truat region (default: 1.0).</span>
<span class="sd">        - eta1: threshold for failed iterations (default: 0.01).</span>
<span class="sd">        - eta2: threshold for very successful iteration (default 0.9).</span>
<span class="sd">        - enlargingFactor: factor used to enlarge the trust region</span>
<span class="sd">          during very successful iterations (default 10).</span>

<span class="sd">    :type parameters: dict(string:float or int)</span>

<span class="sd">    :return: x, messages</span>

<span class="sd">        - x is the solution generated by the algorithm,</span>
<span class="sd">        - messages is a dictionary describing information about the lagorithm</span>

<span class="sd">    :rtype: numpay.array, dict(str:object)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="s1">&#39;Optimization algorithm: Newton with simple bounds [simple_bounds_newton].&#39;</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;proportionAnalyticalHessian&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;proportionAnalyticalHessian&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">simple_bounds_newton_algorithm_for_biogeme</span><span class="p">(</span>
        <span class="n">fct</span><span class="p">,</span> <span class="n">init_betas</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">variable_names</span><span class="p">,</span> <span class="n">parameters</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="bio_bfgs">
<a class="viewcode-back" href="../../code/biogeme/optimization.html#biogeme.optimization.bio_bfgs">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">bio_bfgs</span><span class="p">(</span>
    <span class="n">fct</span><span class="p">:</span> <span class="n">FunctionToMinimize</span><span class="p">,</span>
    <span class="n">init_betas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
    <span class="n">variable_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimization interface for Biogeme, based on BFGS quasi-Newton</span>
<span class="sd">    method with simple bounds.</span>

<span class="sd">    :param fct: object to calculate the objective function and its derivatives.</span>
<span class="sd">    :type fct: algorithms.functionToMinimize</span>

<span class="sd">    :param init_betas: initial value of the parameters.</span>

<span class="sd">    :param bounds: list of tuples (ell,u) containing the lower and upper</span>
<span class="sd">                   bounds for each free</span>
<span class="sd">                   parameter. Note that this algorithm does not support bound</span>
<span class="sd">                   constraints.</span>
<span class="sd">                   Therefore, all the bounds must be None.</span>
<span class="sd">    :type bounds: list(tuples)</span>

<span class="sd">    :param variable_names: names of the variables.</span>
<span class="sd">    :type variable_names: list(str)</span>

<span class="sd">    :param parameters: dict of parameters to be transmitted to the</span>
<span class="sd">        optimization routine:</span>

<span class="sd">        - tolerance: when the relative gradient is below that threshold,</span>
<span class="sd">          the algorithm has reached convergence</span>
<span class="sd">          (default:  :math:`\\varepsilon^{\\frac{1}{3}}`);</span>
<span class="sd">        - steptol: the algorithm stops when the relative change in x</span>
<span class="sd">          is below this threshold. Basically, if p significant digits</span>
<span class="sd">          of x are needed, steptol should be set to 1.0e-p. Default:</span>
<span class="sd">          :math:`10^{-5}`</span>
<span class="sd">        - cgtolerance: when the norm of the residual is below that</span>
<span class="sd">          threshold, the conjugate gradient algorithm has reached</span>
<span class="sd">          convergence (default:  :math:`\\varepsilon^{\\frac{1}{3}}`);</span>
<span class="sd">        - infeasibleConjugateGradient: if True, the conjugate</span>
<span class="sd">          gradient algorithm may generate until termination.  The</span>
<span class="sd">          result will then be projected on the feasible domain.  If</span>
<span class="sd">          False, the algorithm stops as soon as an infeasible iterate</span>
<span class="sd">          is generated (default: False).</span>
<span class="sd">        - maxiter: the maximum number of iterations (default: 1000).</span>
<span class="sd">        - radius: the initial radius of the truat region (default: 1.0).</span>
<span class="sd">        - eta1: threshold for failed iterations (default: 0.01).</span>
<span class="sd">        - eta2: threshold for very successful iteration (default 0.9).</span>
<span class="sd">        - enlargingFactor: factor used to enlarge the trust region</span>
<span class="sd">          during very successful iterations (default 10).</span>

<span class="sd">    :type parameters: dict(string:float or int)</span>

<span class="sd">    :return: x, messages</span>

<span class="sd">        - x is the solution generated by the algorithm,</span>
<span class="sd">        - messages is a dictionary describing information about the algorithm</span>

<span class="sd">    :rtype: numpay.array, dict(str:object)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Optimization algorithm: BFGS with simple bounds [simple_bounds_BFGS].&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;proportionAnalyticalHessian&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;proportionAnalyticalHessian&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">simple_bounds_newton_algorithm_for_biogeme</span><span class="p">(</span>
        <span class="n">fct</span><span class="p">,</span> <span class="n">init_betas</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">variable_names</span><span class="p">,</span> <span class="n">parameters</span>
    <span class="p">)</span></div>



<span class="n">algorithms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;scipy&#39;</span><span class="p">:</span> <span class="n">scipy</span><span class="p">,</span>
    <span class="s1">&#39;LS-newton&#39;</span><span class="p">:</span> <span class="n">newton_linesearch_for_biogeme</span><span class="p">,</span>
    <span class="s1">&#39;TR-newton&#39;</span><span class="p">:</span> <span class="n">newton_trust_region_for_biogeme</span><span class="p">,</span>
    <span class="s1">&#39;LS-BFGS&#39;</span><span class="p">:</span> <span class="n">bfgs_linesearch_for_biogeme</span><span class="p">,</span>
    <span class="s1">&#39;TR-BFGS&#39;</span><span class="p">:</span> <span class="n">bfgs_trust_region_for_biogeme</span><span class="p">,</span>
    <span class="s1">&#39;simple_bounds&#39;</span><span class="p">:</span> <span class="n">simple_bounds_newton_algorithm_for_biogeme</span><span class="p">,</span>
    <span class="s1">&#39;simple_bounds_newton&#39;</span><span class="p">:</span> <span class="n">bio_newton</span><span class="p">,</span>
    <span class="s1">&#39;simple_bounds_BFGS&#39;</span><span class="p">:</span> <span class="n">bio_bfgs</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Michel Bierlaire.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>